{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shortcuts & magics\n",
    "\n",
    "function + P --command pallete\n",
    "\n",
    "shitf + tab -- command/object documentation\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "%ls magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Don't know how to reset  #clear, please run `%reset?` for details\n",
      "Don't know how to reset  namespace, please run `%reset?` for details\n",
      "Flushing input history\n",
      "Don't know how to reset  dictionary, please run `%reset?` for details\n"
     ]
    }
   ],
   "source": [
    "%reset #clear namespace in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-d2e65ad4d999>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#for loop\n",
    "for i in range(5): #range resets the value of i to the next in the arange setup even if it's modified in the loop\n",
    "    # for loop does not just add one every iteration\n",
    "    print(i)\n",
    "    i=i+1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The enemy gets hit for 10 hitpoints\n",
      "The enemy gets hit for 10 hitpoints\n",
      "The enemy gets hit for 10 hitpoints\n",
      "The enemy gets hit for 10 hitpoints\n"
     ]
    }
   ],
   "source": [
    "#printing\n",
    "damage=10\n",
    "print('The enemy gets hit for %d hitpoints' % damage)\n",
    "print('The enemy gets hit for ' + str(damage) + ' hitpoints')\n",
    "print('The enemy gets hit for {} hitpoints'.format(damage))\n",
    "print(\"The enemy gets hit for %d hitpoints\" % damage) # \" and ' are interchangable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_0 = [1 1] \t size= 2 \t shape= (2,) \t type= <class 'numpy.ndarray'>\n",
      "t_1 = [2 2 3] \t size= 3 \t shape= (3,) \t type= <class 'numpy.ndarray'>\n",
      "t_2 = [[1 1]] \t size= 2 \t shape= (1, 2) \t type= <class 'numpy.ndarray'>\n",
      "t_3 = [[1 2 3]\n",
      " [4 5 6]] \t size= 6 \t shape= (2, 3) \t type= <class 'numpy.ndarray'>\n",
      "multiplication= \t [[5 7 9]]\n",
      "zeros= \t [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "ones= \t [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#numpy arrays \n",
    "t1=np.array([1,1]) #vectors\n",
    "t2=np.array([2,2,3])\n",
    "t3=np.array([[1,1]]) #1x2 matrix\n",
    "t4=np.array([[1,2,3],[4,5,6]]) #2x3 matrix\n",
    "list=[t1,t2,t3,t4]\n",
    "for (i,array) in enumerate(list):\n",
    "    print(\"t_%d\" %i,\"=\",array,\"\\t size=\",array.size,\"\\t shape=\",array.shape,\"\\t type=\",type(array))\n",
    "print(\"multiplication= \\t\",np.matmul(t3,t4))\n",
    "print(\"zeros= \\t\",np.zeros([2,3]))\n",
    "print(\"ones= \\t\",np.ones([3,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.- [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "2.- 3.0\n",
      "2.- [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "3.- [[1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "#opening and closing a session\n",
    "sess=tf.Session(config=tf.ConfigProto(log_device_placement=True)) \n",
    "#log_device_placement outputs to the terminal the device used for each operation \n",
    "#allow_soft_placement changes operation to cpu when it can't ve run in gpu and Â¿viceversa?\n",
    "#tf.InteractiveSession() initiates a session but installs itself as default session as well\n",
    "print(\"1.-\",sess.run(tf.zeros([2,3])))\n",
    "sess.close()\n",
    "\n",
    "with tf.Session() as sess: #automatically opens and closes a session\n",
    "#also automatically installs itself as default which is why Interactive session is not use on \"with\" context\n",
    "    test=tf.placeholder(tf.float32)\n",
    "    print(\"2.-\",test.eval(feed_dict={test:3})) \n",
    "    print(\"2.-\",sess.run(tf.zeros([2,3])))\n",
    "    \n",
    "sess=tf.InteractiveSession()\n",
    "print(\"3.-\",sess.run(tf.constant([1,2,3],shape=[1,3])))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------using with context ----------------------------\n",
      "2\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n",
      "[[ 9. 12. 15.]\n",
      " [19. 26. 33.]\n",
      " [29. 40. 51.]]\n",
      "ans is: <class 'numpy.ndarray'> 4 (2, 2)\n",
      "c0 is: <class 'tensorflow.python.framework.ops.Tensor'> \n",
      " <bound method Tensor.eval of <tf.Tensor 'MatMul:0' shape=(2, 2) dtype=float32>> \n",
      " (2, 2) \n",
      " Tensor(\"Rank:0\", shape=(), dtype=int32)\n",
      "evaluated zero tensor = [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "-------------------explicit open/close---------------------------\n",
      "2\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n",
      "[[ 9. 12. 15.]\n",
      " [19. 26. 33.]\n",
      " [29. 40. 51.]]\n"
     ]
    }
   ],
   "source": [
    "#tf constants\n",
    "a0 = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b0 = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c0 = tf.matmul(a0, b0)\n",
    "d0 = tf.matmul(b0,a0)\n",
    "#e = tf.matmul(d,c) throws a dimension error, even if calculation is not run\n",
    "f0 = tf.zeros([2,3])\n",
    "\n",
    "k0=tf.constant(1)\n",
    "l0=tf.constant(2)\n",
    "p0=tf.multiply(l0,k0)\n",
    "#sess.run(p0) #fails as session is closed\n",
    "\n",
    "print(\"------------------using with context ----------------------------\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(p0)) #constant\n",
    "    print(sess.run(c0)) #(2x3)*(3x2)=(2x2)\n",
    "    print(sess.run(d0)) #(3x2)*(2x3)=(3x3)\n",
    "    ans=sess.run(c0)\n",
    "    print(\"ans is:\",type(ans),ans.size,ans.shape)\n",
    "    print(\"c0 is:\",type(c0),\"\\n\",c0.eval,\"\\n\",c0.shape,\"\\n\",tf.rank(c0))\n",
    "    print(\"evaluated zero tensor =\",sess.run(f0))\n",
    "    sess.run(tf.zeros([10],dtype=tf.float64))\n",
    "#sess.run(tf.zeros([10],dtype=tf.float64)) if a session is launched here it returns an error\n",
    "print(\"-------------------explicit open/close---------------------------\")\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(p0))\n",
    "print(sess.run(c0)) #(2x3)*(3x2)=(2x2)\n",
    "print(sess.run(d0)) #(3x2)*(2x3)=(3x3)\n",
    "sess.run(tf.zeros([10],dtype=tf.float64))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p= 3.5\n",
      "bp= [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#tf placeholders\n",
    "with tf.Session() as sess:\n",
    "    p = tf.placeholder(tf.float32)\n",
    "    t = p + 1.5\n",
    "    #t.eval()  # This will fail, since the placeholder did not get a value.\n",
    "    print(\"p=\",t.eval(session=sess,feed_dict={p:2.0}))  # This will succeed because we're feeding a value to the placeholder.\n",
    "\n",
    "a0 = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "bp=tf.placeholder(shape=[2,3],dtype=tf.float64)\n",
    "#sess.run(b) this fails as it need to be fed a value\n",
    "#b.eval(session=sess,feed_dict={b:a}) #it fails as it cannot be fed a tf tensor\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(\"bp=\",bp.eval(session=sess,feed_dict={bp:np.zeros((2,3))})) #success\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "#tf variables\n",
    "a=tf.Variable([[7],[11]], tf.int32)\n",
    "#sess.run(a) #this fails as it needs to be initialized\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(a))\n",
    "#sess.run(a) #this fails as the session is already closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/home/arturo/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/arturo/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-381c2d81ffee>\", line 6, in <module>\n    c = tf.matmul(a, b)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 2122, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4279, in mat_mul\n    name=name)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-381c2d81ffee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Runs the operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/home/arturo/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/arturo/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-381c2d81ffee>\", line 6, in <module>\n    c = tf.matmul(a, b)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 2122, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4279, in mat_mul\n    name=name)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph with operations performed on specified device\n",
    "#with tf.device('/cpu:0'):\n",
    "with tf.device('/device:GPU:0'):    \n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the operation\n",
    "print(sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1) (3,)\n",
      "[[10.]\n",
      " [10.]\n",
      " [10.]] [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#with tf.device('device:GPU:0'):\n",
    "with tf.device('device:CPU:0'):\n",
    "    W = tf.Variable(np.ones([3,10]))\n",
    "    bv = tf.Variable(np.ones([3]))\n",
    "    x=tf.placeholder(shape=[10,1],dtype=tf.float64)\n",
    "    y=tf.matmul(W,x)\n",
    "    print(y.shape,bv.shape)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    yres=sess.run(y,feed_dict={x:np.ones((10,1))})\n",
    "    bres=sess.run(bv)\n",
    "    print(yres,bres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.] [1. 2. 3.] (2,) (3, 2)\n",
      "--------------------\n",
      "mat= [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "s1= [[2. 3.]\n",
      " [2. 3.]\n",
      " [2. 3.]] \n",
      " s2= [[2. 2.]\n",
      " [3. 3.]\n",
      " [4. 4.]] \n",
      " s3= [[2. 3.]\n",
      " [2. 3.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#addig vector to a matrix (through broadcasting)\n",
    "#turns out that you can add a vector, elementwise, to a matrix but only adding horizontally through each row\n",
    "#you also can't transpose a vector of shape=[l] (only one index)\n",
    "#to add vectors vertically you need to transpose the matrix, add, and transpose again\n",
    "mat=tf.ones((3,2))\n",
    "vec=tf.constant([1.,2.],shape=[2])\n",
    "vec2=tf.constant([1.,2.,3.],shape=[3])\n",
    "sum1=vec+mat\n",
    "sum2=tf.transpose(vec2+tf.transpose(mat))\n",
    "sum3=tf.add(vec,mat) #same as 1,adding vec2 would fail as the addition is done over the other dimention \n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(vec),sess.run(vec2),vec.shape,mat.shape)\n",
    "    print(\"--------------------\")\n",
    "    print(\"mat=\",sess.run(mat))\n",
    "    print(\"s1=\",sess.run(sum1),\"\\n s2=\",sess.run(sum2),\"\\n s3=\",sess.run(sum3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100) (10, 100) (10,)\n"
     ]
    }
   ],
   "source": [
    "#example of adding vector and matrix\n",
    "x = tf.placeholder(tf.float32, [100, 784])\n",
    "W = tf.Variable(tf.ones([10,784]))\n",
    "b = tf.Variable(tf.ones([10]))\n",
    "prod=tf.matmul(W,x,transpose_b=True)\n",
    "y=tf.transpose(tf.transpose(prod)+ b)\n",
    "#d = b + tf.matmul(W,x,transpose_b=True)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "#batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#print(sess.run(y, feed_dict={x: np.ones((100,784))}))\n",
    "#print(sess.run(y, feed_dict={x: np.ones((100,784))}))\n",
    "print(prod.shape,y.shape,b.shape)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]] \n",
      " [1. 2. 3. 4.]\n",
      "[[0.09003057 0.24472848 0.66524094]\n",
      " [0.09003057 0.24472848 0.66524094]]\n",
      "[0.0320586  0.08714432 0.23688284 0.6439143 ]\n",
      "[[0.26894143 0.7310586 ]]\n",
      "[[1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#softmax normalization on matrices\n",
    "A=tf.constant([1.,2.,3.,1.,2.,3.],shape=[2,3])\n",
    "B=tf.constant([1.,2.,3.,4.],shape=[4])\n",
    "C=tf.constant([1.,2.],shape=[1,2])\n",
    "D=tf.constant([1.,2.],shape=[2,1])\n",
    "with tf.Session() as sess:\n",
    "    print(A.eval(),\"\\n\",B.eval())\n",
    "    print(tf.nn.softmax(A).eval())\n",
    "    print(tf.nn.softmax(B).eval())\n",
    "    print(tf.nn.softmax(C).eval())\n",
    "    print(tf.nn.softmax(D).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2] <class 'numpy.ndarray'> (2,)\n",
      "[False  True False] <class 'numpy.ndarray'> (3,)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "argmax=tf.argmax(tf.constant([1,2,7,8,-3,2,4,3],shape=[2,4]),1) #returns index of maximum value across direction 1\n",
    "equal=tf.equal(tf.constant([1,2,3]),tf.constant([3,2,1])) #outputs boolean np.array\n",
    "cast=tf.cast(np.array([True,False]),tf.float32) #converts boolean np.array to numerical array of 1's and 0's\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(argmax),type(sess.run(argmax)),sess.run(argmax).shape)\n",
    "    print(sess.run(equal),type(sess.run(equal)),sess.run(equal).shape)\n",
    "    print(sess.run(cast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Don't know how to reset  #clear, please run `%reset?` for details\n",
      "Don't know how to reset  namespace, please run `%reset?` for details\n",
      "Flushing input history\n",
      "Don't know how to reset  dictionary, please run `%reset?` for details\n"
     ]
    }
   ],
   "source": [
    "%reset #clear namespace in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-d2e65ad4d999>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/arturo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 91.86000227928162 %\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784]) #example vectors are horizontal here so we'll transpose it on multiplication\n",
    "W = tf.Variable(tf.zeros([10,784]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prod=tf.matmul(W,X,transpose_b=True)\n",
    "sumation=tf.transpose(tf.transpose(prod) + b) #add b vertically (column by column) to the matrix\n",
    "Ymod = tf.nn.softmax(tf.transpose(sumation)) #example label vectors are horizontal now,softmax normalization is applied this way\n",
    "Ydata = tf.placeholder(tf.float32, [None, 10]) #validation label vectors are also horizontal \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Ydata * tf.log(Ymod), reduction_indices=[1])) \n",
    "# corss_entropy returns a single vector of the same size as the sample batch\n",
    "# each entry is the cross entropy calculated for a particular example\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(1000): #use SGD with 100 samples (1/550th of total examples)\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={X: batch_xs, Ydata: batch_ys})\n",
    "correct_prediction = tf.equal(tf.argmax(Ymod,1), tf.argmax(Ydata,1)) #compares horizontally,i.e. component of each vector\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #percentage of correct predictions\n",
    "acc=sess.run(accuracy, feed_dict={X: mnist.test.images, Ydata: mnist.test.labels})\n",
    "sess.close()\n",
    "print(\"Accuracy is\", acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dictionary vs List vs Set**\n",
    "\n",
    "A list keeps order, dict and set don't: when you care about order, therefore, you must use list (if your choice of containers is limited to these three, of course;-).\n",
    "\n",
    "dict associates with each key a value, while list and set just contain values: very different use cases, obviously.\n",
    "\n",
    "set requires items to be hashable, list doesn't: if you have non-hashable items, therefore, you cannot use set and must instead use list.\n",
    "\n",
    "set forbids duplicates, list does not: also a crucial distinction. (A \"multiset\", which maps duplicates into a different count for items present more than once, can be found in collections.Counter -- you could build one as a dict, if for some weird reason you couldn't import collections, or, in pre-2.7 Python as a collections.defaultdict(int), using the items as keys and the associated value as the count).\n",
    "\n",
    "Checking for membership of a value in a set (or dict, for keys) is blazingly fast (taking about a constant, short time), while in a list it takes time proportional to the list's length in the average and worst cases. So, if you have hashable items, don't care either way about order or duplicates, and want speedy membership checking, set is better than list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d', 'a', ':', '2', '1', '5', 'p'}\n",
      "{'pear', 'banana', 'orange', 'apple'}\n",
      "True\n",
      "False\n",
      "{'d', 'a', 'c', 'r', 'b'}\n",
      "{'d', 'r', 'b'}\n",
      "{'d', 'a', 'l', 'c', 'r', 'z', 'm', 'b'}\n",
      "{'c', 'a'}\n",
      "{'d', 'z', 'r', 'm', 'l', 'b'}\n"
     ]
    }
   ],
   "source": [
    "testset=set(\"125pa:da\")\n",
    "print(testset)\n",
    "#testset[1] #this would fail as set objects don't support indexing\n",
    "basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n",
    "print(basket)                      # show that duplicates have been removed\n",
    "print('orange' in basket)                 # fast membership testing\n",
    "print('crabgrass' in basket)\n",
    "\n",
    "# Demonstrate set operations on unique letters from two words\n",
    "a = set('abracadabra')\n",
    "b = set('alacazam')\n",
    "print(a)                                  # unique letters in a\n",
    "print(a - b)                              # letters in a but not in b\n",
    "print(a | b)                              # letters in a or b or both\n",
    "print(a & b)                              # letters in both a and b\n",
    "print(a ^ b)                              # letters in a or b but not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> \n",
      " {'a': <tf.Tensor 'Const_11:0' shape=() dtype=float32>, 'b': <tf.Tensor 'Const_12:0' shape=() dtype=float32>}\n",
      "Tensor(\"Const_11:0\", shape=(), dtype=float32) Tensor(\"Const_12:0\", shape=(), dtype=float32) \n",
      "\n",
      "Tensor(\"Const_11:0\", shape=(), dtype=float32) Tensor(\"Const_12:0\", shape=(), dtype=float32) \n",
      "\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#dictionary:associates a value to a key\n",
    "test={'a':tf.constant(1.0),'b':tf.constant(2.0)}\n",
    "print(type(test),\"\\n\",test) #this is a dictionary\n",
    "print(test[\"a\"],test[\"b\"],\"\\n\")#using \" or ' is indifferent\n",
    "print(test['a'],test['b'],\"\\n\")\n",
    "print(type(test[\"a\"]),type(tf.constant(1.9)))\n",
    "#test[[1]] fails as it is not a key\n",
    "#dictionaries and sets don't support indexing and thus fails when calling an element via an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbb2b468d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tf normal distirbution\n",
    "xt=tf.random_normal([1000])\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    xf=sess.run(xt)\n",
    "#plt.plot(xf);\n",
    "plt.hist(xf,label='xf');\n",
    "plt.plot(np.histogram(xf)[0],label='hist1'); #actual histogram\n",
    "plt.plot(np.histogram(xf)[1],label='hist2'); #interval edges\n",
    "plt.plot(np.zeros(10));\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 0.]\n",
      "[array([ 0.8609506 , -0.5508698 , -1.5939314 , -0.5930425 , -0.7570683 ,\n",
      "        0.4917225 ,  1.2102869 , -0.9644545 ,  0.81396276,  0.8768675 ,\n",
      "        1.6029515 ], dtype=float32), array([0.8609506 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.4917225 , 1.2102869 , 0.        , 0.81396276, 0.8768675 ,\n",
      "       1.6029515 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#relu\n",
    "rand_test=tf.random_normal([11])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.nn.relu(tf.constant([3.0,-1.0]))))\n",
    "    print(sess.run([rand_test,tf.nn.relu(rand_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-d35d5c00cd6d>:40: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Epoch 0 completed out of 10 loss: 1814826.3556518555\n",
      "Epoch 1 completed out of 10 loss: 399599.07353782654\n",
      "Epoch 2 completed out of 10 loss: 239485.88409876823\n",
      "Epoch 3 completed out of 10 loss: 137350.22784757614\n",
      "Epoch 4 completed out of 10 loss: 84064.72156804055\n",
      "Epoch 5 completed out of 10 loss: 54389.01516051885\n",
      "Epoch 6 completed out of 10 loss: 37015.26285100728\n",
      "Epoch 7 completed out of 10 loss: 29588.45100973494\n",
      "Epoch 8 completed out of 10 loss: 22324.26003158326\n",
      "Epoch 9 completed out of 10 loss: 21522.871839657426\n",
      "Accuracy: 0.9534\n"
     ]
    }
   ],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "n_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder('float', [None, 784])\n",
    "Ydata = tf.placeholder('float')\n",
    "\n",
    "def neural_network_model(X):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    l1 = tf.add(tf.matmul(X,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(X):\n",
    "    Ymod = neural_network_model(X)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Ymod, labels=Ydata) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    hm_epochs = 10\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={X: epoch_x, Ydata: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(Ymod, 1), tf.argmax(Ydata, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({X:mnist.test.images, Ydata:mnist.test.labels}))\n",
    "\n",
    "train_neural_network(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss: 1726790.301574707\n",
      "Epoch 1 completed out of 10 loss: 414326.28814315796\n",
      "Epoch 2 completed out of 10 loss: 225333.56244516373\n",
      "Epoch 3 completed out of 10 loss: 145023.311981034\n",
      "Epoch 4 completed out of 10 loss: 87469.92254096025\n",
      "Epoch 5 completed out of 10 loss: 63491.66683602333\n",
      "Epoch 6 completed out of 10 loss: 40219.441332149414\n",
      "Epoch 7 completed out of 10 loss: 32213.44969384931\n",
      "Epoch 8 completed out of 10 loss: 22937.026453024147\n",
      "Epoch 9 completed out of 10 loss: 19589.49233396165\n",
      "Accuracy: 0.9508\n"
     ]
    }
   ],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "n_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def neural_network_model(data):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    hm_epochs = 10\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
