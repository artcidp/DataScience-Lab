{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habíamos discutido previamente la separación de datos en entrenamiento y prueba, así como la distinción y entre parámetros e hiperparámetros. Con esto, podemos entener la introducción de una separación adicional de los datos: **validación**.\n",
    "\n",
    "**Datos de Entrenamiento:** Dados un conjunto de hiperparámetros, se utilizan para entrenar el algoritmo y ajustar los parámetros (internos). Por esta misma razón, usualmente componen la mayoría de los datos.\n",
    "\n",
    "**Datos de Validación:** Se utiliza para evaluar el rendimiento del modelo creado con los datos de entrenamiento, así como seleccionar o validar los distintos hiperparámetros (externos) en función de las métricas correspondientes.\n",
    "\n",
    "**Datos de Prueba:** Una vez que se hallan ajustado los parámetros (entrenamiento) e hiperparámetros (validación), se utilizan los datos de prueba para generar una métrica final de evaluación de un algoritmo. En esta etapa es en la que se comparan diferentes algoritmos a utilizar (e.g: Random Forest vs SVM). \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/960/1*Nv2NNALuokZEcV6hYEHdGA.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosotros no habíamos hecho una distinción real entre validación y prueba. Habíamos comparado el rendimiento de un modelo entrenado con diferentes híperparámetros y seleccionado el que daba la mejor estimación. A esto le llamamos prueba, aunque formalmente sería un conjunto de validación. La etapa de prueba, únicamente consistiría en evaluar el modelo óptimo hallado con un conjunto de datos distinto.\n",
    "\n",
    "En este caso, las funciones que habíamos visto con sci-kit learn como: `train_test_split()`, `cross_val_predict()` y `GridSearchCV()` hacen una división en 2 partes. Una la podemos utilizar para entrenamiento y la otra para validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es típico realizar una separación de los datos en: 60% entrenamiento, 20% validación y 20% prueba. Sin embargo, esto puede variar según la cantidad de datos requeridos para el entrenamiento, el número de híperparámetros, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El desarrollo de redes neuronales se remonta a mediados del siglo XX.\n",
    "\n",
    "- En 1943, Warren McCulloch y Walter Pitts publican uno de los primeros modelos matemáticos de la neurona, basado en circuitos eléctricos. Describieron una neurona como una compuerta lógica con salida binaria; multiples señales entran por las dendritas y, si estas exceden un umbral específico se envía una señal por el axón. [[link]](http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf)\n",
    "\n",
    "<img src=\"https://blog.godatadriven.com/images/rod-multi-threshold-neuron/artificial_neuron.png\">\n",
    "\n",
    "El esquema básico utilizado es el siguiente:\n",
    "\n",
    "<img src=\"images/mcp_model.png\" width=500>\n",
    "\n",
    "**Obs:** Esto equivale a decir que si hay n o más señales que entran a la neurona, esta se activa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Durante la decada de 1950, Nathaniel Rochester de IBM Labs realizó el primer esfuerzo en simular computacionalmente una red neuronal.\n",
    "- En 1957, Frank Rosenblatt desarolló un algoritmo basado en este modelo neuronal (el Perceptrón), el cual es un clasificador lineal binario que incorpora pesos a las entradas. [[link]](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/perceptron_model.png\" width=500>\n",
    "\n",
    "**Obs:** \n",
    "- Ya no es necesario que las entradas $x_i$ sean binarias, puesto que los pesos $w_i$ ajustan el valor de entrada a la suma con valores no-enteros.\n",
    "- Este modelo de la neurona utiliza las siguientes ideas: activación binaria (todo o nada), influencia pesada de una sola sinápsis (pesos) e influencia acumulada de diferentes sinapsis (suma).\n",
    "- Este modelo NO considera algunas caracteristicas de neuronas reales: periodo refractario, bifurcación de axones y dendritas, comportamiento temporal, etc.\n",
    "\n",
    "<img src=\"https://www.ebi.ac.uk/biomodels-static/ModelMonth/2010-05/figure1.png\" width=500>\n",
    "\n",
    "Otra forma común de dibujar el diagrama es la siguiente:\n",
    "\n",
    "<img src=\"images/perceptron_model5.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos matemáticos, esto representa la ecuación:\n",
    "\n",
    "$$H(\\sum_{i=1}^N w_i x_i+b)=H(\\mathbf{w}^\\intercal \\mathbf{x}+b), \\quad (1)$$ \n",
    "\n",
    "donde $H(t)$ es la función de Heaviside o función escalón y representa la \"activación\" de la neurona. Por esa razon, en este contexto también se le llama **función de activación**. \n",
    "\n",
    "Recordamos que $\\mathbf{w}^\\intercal \\mathbf{x}+b=0$ representa un plano en $N$ dimensiones. Esta será la función de decisión en la clasificación del perceptrón (aunque también puede usarse la función $\\text{sign}$ como en las SVMs u otras funciones).\n",
    "\n",
    "<img src=\"images/svm_linsep.png\">\n",
    "\n",
    " Al igual que con las SVMs, nosotros deseamos encontar un plano que separe los datos (asumiendo que estos son linealmente separables). Sin embargo, la forma de hallarlo en este caso es diferente. Supongamos que tenemos una base de datos $\\mathbf{x}_1,...,\\mathbf{x}_d$, con etiquetas $y_1,...,y_d \\in {0,1}$. Entonces, el algoritmo del perceptrón es:\n",
    " \n",
    "1. Inicializar $\\mathbf{w}$ y $b$. Puede ser de manera aleatoria, con ceros o unos.\n",
    "2. Si el algoritmo no da una clasificación perfecta, seleccionar $\\mathbf{x}_i,y_i$ de manera aleatoria.\n",
    "3. Si $y_i=1$ (SPG arriba del plano) y $\\mathbf{w}^\\intercal \\mathbf{x}_i+b<0$ (está debajo del plano): $\\mathbf{w}_{new}=\\mathbf{w}+\\mathbf{x}_i$.\n",
    "4. Si $y_i=0$ (abajo del plano) y $\\mathbf{w}^\\intercal \\mathbf{x}_i+b\\geq 0$ (está arriba del plano) $\\mathbf{w}_{new}=\\mathbf{w}-\\mathbf{x}_i$.\n",
    "5. Repetir los pasos 2 a 4 hasta que el algoritmo converja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué utilizamos las ecuaciones en los pasos 3 y 4 para cambiar el valor de $\\mathbf{w}$? Para esto recordemos que el producto punto entre dos vectores se puede escribir como: $\\mathbf{w}^\\intercal \\mathbf{x}= ||\\mathbf{w}||||\\mathbf{x}|| cos\\alpha$, i.e.\n",
    "\n",
    "$$cos\\alpha= \\frac{\\mathbf{w}^\\intercal \\mathbf{x}}{||\\mathbf{w}||||\\mathbf{x}||}. \\quad (2)$$\n",
    "\n",
    "Por lo tanto:\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{Si}\\quad & \\mathbf{w}^\\intercal \\mathbf{x} >0 \\implies cos\\alpha>0 \\implies \\alpha<90°,\\\\\n",
    "{y\\ si} \\quad & \\mathbf{w}^\\intercal \\mathbf{x}<0 \\implies cos\\alpha<0 \\implies \\alpha>90°.\n",
    "\\end{align}$\n",
    "\n",
    "Esto significa que, cuando converja, $\\mathbf{w}$ tendrá un ángulo menor a 90° con los vectores arriba del plano y menor a 90° con los vectores abajo del plano.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*D09EzbR-sGbX-qv2jcEPhw.png\">\n",
    "\n",
    "Por lo tanto, al calcular $\\mathbf{w}_{new}$ se tienen los siguientes casos:\n",
    "\n",
    "<img src=\"images\\alpha new esp.png\">\n",
    "\n",
    "Esto significa que, conforme calculamos nuevos valores de $\\mathbf{w}$, los ángulos del vector normal, convergen al valor deseado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede demostrar que el algoritmo converge bajo ciertas condiciones (e.g. datos linealmente separables). [[link]](http://www.cs.columbia.edu/~mcollins/courses/6998-2012/notes/perc.converge.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalización del Perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un principio, el perceptrón parecía ser un algoritmo muy poderoso para clasificar datos. Sin embargo, no tomó mucho tiempo para que sus deficiencias comenzaran  a ser evidentes.\n",
    "\n",
    "En primer lugar, dado que es un algoritmo de clasificación lineal, existen distribuciones de datos que éste no puede clasificar.  Una de ellas es la de la función XOR.\n",
    "\n",
    "<img src=\"images/cropped logic separability.jpeg\">\n",
    "\n",
    "Dado que la forma básica del Perceptrón puede pensarse como una sola neurona, el siguiente paso fue crear una red de neuronas que utilizaban el modelo del perceptrón.\n",
    "\n",
    "<img src=\"images/mlp_model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto representa un sistema de ecuaciones:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y_1=H(\\sum_{i=1}^N w_{1,i} x_i+b_1)&=H(\\mathbf{w}_1^\\intercal \\mathbf{x}+b_1)\\\\\n",
    "y_2=H(\\sum_{i=1}^N w_{2,i} x_i+b_2)&=H(\\mathbf{w}_2^\\intercal \\mathbf{x}+b_2) \\quad (3) \\\\\n",
    "y_3=H(\\sum_{i=1}^N w_{3,i} x_i+b_3)&=H(\\mathbf{w}_3^\\intercal \\mathbf{x}+b_3),\n",
    "\\end{cases}$$ \n",
    "\n",
    "el cual se puede escribir como una ecuación vectorial:\n",
    "\n",
    "$$\\mathbf{y}=H(\\mathbf{W} \\mathbf{x}+\\mathbf{b}), \\quad(4)$$\n",
    "\n",
    "donde $\\mathbf{y}=(y_1,y_2,y_3)^\\intercal$, $\\mathbf{b}=(b_1,b_2,b_3)^\\intercal$, $\\mathbf{W}=\\begin{pmatrix}\n",
    "w_{1,1} & \\ldots & w_{1,N} \\\\\n",
    "w_{2,1} & \\ldots & w_{2,N} \\\\\n",
    "w_{3,1} & \\ldots & w_{3,N}\\end{pmatrix}$ y $H$ es una función que actúa en cada coordenada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diagrama se suele simplificar, graficándolo de la siguiente manera:\n",
    "\n",
    "<img src=\"images/mlp_mod_simple.png\" width=500>\n",
    "\n",
    "Aquí $O_i$ representa una \"capa\" de neuronas, cada una de las cuales realiza las operaciones dadas por alguna de las ecuaciones en (3).\n",
    "\n",
    "**Nota:** La función de activación $H$ puede o no ser importante indicar en el diagrama. Cuando no se requiere espicificar se omite en el diagrama de arriba, dando por entendido que se incluye en las operaciones de la capa de salida.\n",
    "\n",
    "Finalmente, en el siguiente diagrama hemos añadido una capa adicional de neuronas.\n",
    "\n",
    "<img src=\"images/mlp_model_hidden.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha llegado el momento para hablar sobre diferentes conceptos importantes en el caso de redes neuronales: \n",
    "\n",
    "- **Capa de Entrada:** Es el conjunto de nodos conformado por $x_1,...,x_N$, donde se ingresan los datos. También se le llama capa expuesta o visible.\n",
    "- **Capa de Salida:** El conjuto de nodos formado por $O_1,O_2,O_3$, son las últimas que existen antes de tener el resultado final $y_i$. \n",
    "- **Capa(s) Oculta(s):** Son todas las capas que existen entre las de entrada y salida, aquí sólo se representó una capa con 2 neuronas: $H_1,H_2$.\n",
    "\n",
    "\n",
    "- **Tamaño de la Red Neuronal:** Número de nodos (neuronas) en el modelo.\n",
    "- **Ancho de una Capa:** Número de neuronas en la capa. Es el número de filas en la matriz $\\mathbf{W}$ correspondiente a la capa.\n",
    "- **Produndidad de una Red Neuronal:** Número de capas en una red. Cuando se tiene un gran número de capas, se le conoce como aprendizaje profundo (Deep Learning). \n",
    "- **Capacidad o Complejidad de una Red Neuronal:** El tipo de funciones o estructuras que puede reproducir una red. También llamada capacidad de representación.\n",
    "- **Arquitectura de una Red Neuronal:** El arreglo específico de las neuronas y las funciones de activación $H$ utilizadas. \n",
    "\n",
    "\n",
    "- **Conexión de Neuronas:** Un par de neuronas estan conectadas si la de la capa posterior recibe una señal de la neurona de la capa anterior. Esto es análogo a una sinápsis.\n",
    "- **Red Completamente Conectada:** Tipo de red en la que todas las neuronas de todas las capas tienen una conexión con cada neurona de la capa anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo específico es una generalización del Perceptrón y se le conoce como Perceptrón de Múltiples Capas (MLP en inglés). \n",
    "\n",
    "Dado que la función representada ahora, en general, no es un plano, se necesita un método diferente de optimización para obtener los valores finales de los pesos en la red. Lo que se suele hacer es calcular una función de error, la cual queremos minimizar en función de los pesos de la red. Típicamente se utiliza:\n",
    "\n",
    "$$\\mathcal{L}(\\mathbf{X},\\mathbf{y}_{actual},\\mathcal{W},\\mathcal{b})=\\frac{1}{2}\\sum_{i=1}^N||\\mathbf{y}_{i\\ pred}(\\mathbf{x}_i,\\mathcal{W},\\mathcal{b})-\\mathbf{y}_{i\\ actual}||^2. \\quad (5)$$\n",
    "\n",
    "Esto se hace calculando el gradiente de la función con respecto a los pesos y \"descendiendo\" de manera iterada para reducir el error. Más adelante veremos cómo se hace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Persisten los Problemas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente diagrama muestra los tipos de regiones que puede crear una red neuronal según el número de capas que se utilicen:\n",
    "\n",
    "<img src=\"images/linsep layers.png\">\n",
    "\n",
    "Notemos que este tipo de algoritmos sí puede resolver el problema de la función XOR!!!\n",
    "\n",
    "**Importante:**\n",
    "En general, cada neurona en una red puede pensarse como un plano de separación. Varias neuronas en una capa permiten intersectar las regiones generadas por varios planos y crear regiones convexas como se ve en la figura. Al añadir capas, las regiones pueden sumarse o restarse para crear patrones más complejos. Por lo tanto, las redes neuronales se pueden interpretar como aproximadores de funciones, con la complejidad variando según la arquitectura de la red neuronal. Este es un resultado teórico que se conoce como el **Teorema de Aproximación Universal.** [[link]](https://en.wikipedia.org/wiki/Universal_approximation_theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior es una propiedad excelente de las redes neuronales. Sin embargo, tienen algunas desventajas importantes:\n",
    "\n",
    "- Si se usa la función de activación de Heaviside (función escalón), la derivada no está definida en 0, por lo que el gradiente no podrá ser utilizado para minimizar la función de error. Para solucionar esto se utilizan distintas funciones de activación.\n",
    "- Debido a las estructuras de las redes, el número de derivadas que tienen que obtenerse mediante la regla de la cadena crece exponencialmente con el número de capas utilizadas. Existe un método llamado \"Backpropagation\", desarrollado en los 60s y re-descubierto en los 80s que permite reducir el número de derivadas calculadas. \n",
    "- En la práctica, las redes pueden tener millones de parámetros!! Esto hace que visualizar el problema sea muy complicado.\n",
    "- Una vez calculado el gradiente, no se tiene garantía de que se halle un mínimo global de la función, pues puede haber mínimos locales, donde se halla el mínimo, i.e. la superficie de la función de error no es necesariamente convexa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El Invierno de la Inteligencia Artificial**\n",
    "\n",
    "Estos fueron los principales problemas que enfrentaron las redes neuronales en los 60s. Marvin L. Minsky y Seimour A. Papert publicaron un libro llamado \"Perceptrones\" en 1969 en donde criticaron el uso de perceptrones en su versión general de múltiples capas. [[link]](https://drive.google.com/file/d/1UsoYSWypNjRth-Xs81FsoyqWDSdnhjIB/view) Este libro causó que la comunidad científica perdiese interés en las redes neuronales hasta los 80s.\n",
    "\n",
    "En 1985, Rumelhart, Hinton, y Williams hicieron una recopilación de avances independientes que habían hecho en las últimas décadas (incluyendo Backpropagation), lo cual reinvigoró la investigación en el campo.[[link]](https://stanford.edu/~jlmcc/papers/PDP/Volume%201/Chap8_PDP86.pdf) A continuación veremos los avances más importantes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de Activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representan la activación de una o varias neuronas según sus entradas. La idea es que sus derivadas estén definidas en todo su dominio para que el gradiente de la función de error esté bien definido. Veremos las más comunes:\n",
    "\n",
    "**Logística:** $f(x) = \\frac{1}{1 + e^{-x}} = \\frac{e^x}{e^x + 1} = \\tfrac12 + \\tfrac12 \\tanh(\\tfrac{x}{2})$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Activation_logistic.svg/1920px-Activation_logistic.svg.png\" width=300>\n",
    "\n",
    "**Tanh:** $f(x) = \\tanh x = \\frac{\\sinh x}{\\cosh x} = \\frac {e^x - e^{-x}} {e^x + e^{-x}}\n",
    "  = \\frac{e^{2x} - 1} {e^{2x} + 1}$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Activation_tanh.svg/1920px-Activation_tanh.svg.png\" width=300>\n",
    "\n",
    "**SoftSign:** $f(x)= \\frac{1}{1+|x|}$\n",
    "\n",
    "<img src=\"images/softsign.png\" width=300>\n",
    "\n",
    "\n",
    "**Rectified Linear Unit (ReLU):** $f(x) = x^+ = \\max(0, x)$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_rectified_linear.svg/1920px-Activation_rectified_linear.svg.png\" width=300>\n",
    "\n",
    "Notemos que esta no es diferenciable en 0. ReLU tiene una familia de funciones asociadas que modifican sus propiedades.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Sepp_Hochreiter/publication/284579051/figure/fig1/AS:614057178578955@1523414048184/The-rectified-linear-unit-ReLU-the-leaky-ReLU-LReLU-a-01-the-shifted-ReLUs.png\" width=500>\n",
    "\n",
    "**Soft Plus:** $f(x)=ln(1+e^x)$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Activation_softplus.svg/1920px-Activation_softplus.svg.png\" width=300>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, existen funciones de activación que toman como entrada vectores en vez de escalares,i.e. todas las salidas de una capa de neuronas:\n",
    "\n",
    "**Softmax:** $f_i(\\mathbf{x})=\\frac{e^{x_i}}{\\sum_{k=0}^N e^{x_k}}$. Se utiliza para normalizar las salidas de una capa de neuronas,típicamente en la capa de salida.\n",
    "\n",
    "**Maxout:** $f(\\mathbf{x})=\\max_i x_i$\n",
    "\n",
    "Puedes ver una lista más completa de funciones de activación [aquí](https://en.wikipedia.org/wiki/Activation_function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos una red neuronal como la que se muesra en la figura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz16.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el gradiente de la función de error, debemos obtener las derivadas de cada uno de los pesos que existen en la red: $w^l_{jk}$. Esto significa que, para obtener las derivadas de los valores de las últimas capas, utilizando la regla de la cadena, debemos calcular todas las derivadas anteriores que influyen en $w^l_{jk}$.\n",
    "\n",
    "La idea básica del algoritmo es reutilizar las derivadas calculadas en las primeras capas cuando se calculan las derivadas en las últimas capas. Con esto, aprovechamos el hecho de que la capa $l$ solo recibe influencias directamente de la capa $l-1$.\n",
    "\n",
    "Al final, utilizar este truco hace que el algoritmo de Backpropagation sea más eficiente que el cálculo por fuerza bruta. En lugar de aumentar exponencialmente con el número de capas $L$, Backpropagation aumenta el número de calculos de manera lineal en $L$. A sí mismo, si todas las capas tienen el mismo $K$ ancho, el número de operaciones que se requieren aumenta conforme $K^2$.\n",
    "\n",
    "Puedes leer más acerca de la decucción matemática [aquí](http://neuralnetworksanddeeplearning.com/chap2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay distintos algoritmos que se utilizan para cambiar los valores de los pesos, según el gradiente calculado mediante Backpropagation $\\nabla_\\mathcal{W}\\mathcal{L}(\\mathbf{X},\\mathbf{y},\\mathcal{W})$. Veremos los más comunes:\n",
    "\n",
    "**Batch Gradient Descent:** $\\mathcal{W}_{new}=\\mathcal{W}-\\eta \\nabla_\\mathcal{W}\\mathcal{L}(\\mathbf{X},\\mathcal{W})$\n",
    "\n",
    "Este método consiste en calcular el gradiente en toda la base de datos y modificar el valor de los pesos según la **tasa de aprendizaje** $\\eta$.\n",
    "\n",
    "**Stocastich Gradient Descent:** $\\mathcal{W}_{new}=\\mathcal{W}-\\eta \\nabla_\\mathcal{W}\\mathcal{L}(\\mathbf{x}_i,y_i,\\mathcal{W})$.\n",
    "\n",
    "Calcula el gradiente con una función de error que depende de sólo un punto $x_i$, $y_i$ seleccionado al azar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini Batch Gradient Descent:** $\\mathcal{W}_{new}=\\mathcal{W}-\\eta \\nabla_\\mathcal{W}\\mathcal{L}(\\mathbf{x}_{(i,i+n)},y_{(i,i+n)},\\mathcal{W})$\n",
    "\n",
    "Calcula el gradiente utilizando una muestra aleatorea de los datos de entrenamiento. También tiene un comportamiento estocástico y a veces también se le llama Stochastic Gradient Descent.\n",
    "\n",
    "**Método de Momento:** $\\begin{align} \\mathcal{W}_{t+1}&=\\mathcal{W}_t- v_t\\\\\n",
    "v_t&=\\gamma v_{t-1} + \\eta \\nabla_\\mathcal{W}\\mathcal{L}(\\mathbf{X},\\mathcal{W}_t)\n",
    "\\end{align}$\n",
    "\n",
    "Añade una fracción $\\gamma$ del cambio anterior al nuevo cambio, de modo que la función puede \"acelerar\" su decenso cuando la pendiente es considerable.\n",
    "\n",
    "**Nesterov Accelerated Gradient (NAG):** $\\begin{align} \\mathcal{W}_{t+1}&=\\mathcal{W}_t- v_t\\\\\n",
    "v_t&=\\gamma v_{t-1} + \\eta \\nabla_\\mathcal{W}\\mathcal{L}(\\mathbf{X},\\mathcal{W}_t-\\gamma v_{t-1})\n",
    "\\end{align}$\n",
    "\n",
    "Modifica los parámetros, añadiendo $-\\gamma v_{t-1}$. Esto es una aproximación del gradiente en el siguiente paso, por lo que \"anticipa\" la próxima iteración y evita acelerar demasiado rápido cuando se encuentra cerca de un mínimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adagrad:** $\\begin{align} w_{i\\ t+1}&=w_i - \\frac{\\eta}{\\sqrt{G_{t\\ i}+\\epsilon}} \\nabla_i\\mathcal{w}\\mathcal{L}(\\mathbf{X},\\mathcal{W})\\\\\n",
    "\\mathcal{w}_{t+1}&=\\mathcal{w}_t - \\frac{\\eta}{\\sqrt{G_t+\\epsilon}}\\odot \\nabla \\mathcal{w}\\mathcal{L}(\\mathbf{X},\\mathcal{W}_t)\n",
    "\\end{align}$\n",
    "\n",
    "Modifica la taza de aprendizaje añadiendo un vector $G$, que contiene en la entrara $G_{i}$ la suma de los cuadrados de todos los gradientes anteriores con respecto a $w_i$. $\\epsilon$ es un número pequeño que se introduce para evitar que el denominador sea cero. Esto hace que la taza de aprendizaje se adapte según los gradientes que vaya encontrando el algoritmo.\n",
    "\n",
    "$\\odot$ representa el producto de Hadamard, que simboliza multiplicar coordenada a coordenada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif\">\n",
    "\n",
    "<img src=\"http://ruder.io/content/images/2016/09/saddle_point_evaluation_optimizers.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación con Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los avences teóricos que hemos visto hasta ahora parecían resolver los problemas existentes con las redes neuronales. Sin embargo, en los 90s el principal problema era más práctico: la falta de capacidad de cómputo. Esto ocasiono que no hubiese mucho desarrollo hasta la década de los 2000s, cuando hubo disponibilidad de tarjetas gráficas y procesadores lo suficientemente poderosos como para poder implementar fácilmente las redes neuronales. Esto también se debió a resultados académicos importantes: \n",
    "\n",
    "- En 2009, Geoff Hinton publicó un artículo en el que utilizaba una red neuronal de gran profundidad para reconocimiento de voz. Pudo entrenar la red en cuestió de semanas, mientras que algoritmos previos con resultados similares tardaban meses en entrenar. \n",
    "- En 2012, su estudiante Alex Krizhevsky utilizó una red neuronal (AlexNet) en el  ImageNet Large Scale Visual Recognition Challenge. Obtuvo un error top-5 de 15.3%, 10.8% menor al segundo lugar en la competencia.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1536/1*qyc21qM0oxWEuRaj-XJKcw.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto causó un gran impacto en el campo de las redes neuronales y atrajo intereses de grandes compañías como Google y Facebook, quienes desarrollaron sus propias plataformas de Deep Learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://api.ning.com/files/iUa255heshidpDsSwfWRlUtCcHMETbzaB2Z-xm3yfFL22WrV5nEW3fGwgeIn63vwgfrnWnQrQmm3LqTEedLWjSQPcqjx8sts/prg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Tensoflow** \n",
    "- Es la librería con mayor participación de colaboradores en Github.\n",
    "- Desarrollada por Google. Se utiliza en la mayoría de sus servicios.\n",
    "- Principamente se utiliza en Python, pero se están desarrollando versiones para C++, Java, Go, Julia, entre otros.\n",
    "- La herramienta [Tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard) permite visualizar los componentes de la red neuronal.\n",
    "- Tiene extensiones que le permiten ejecutarse de manera distribuida en distintos equipos (Tensorflow Serving) y en celulares (Tensorflow Lite).\n",
    "- Es compatible con CUDA, por lo que puede utilizar GPUs de NVIDIA para ejecutar el código.\n",
    "- Es una librería de bajo nivel, por lo que requiere que se definan explícitamente las variables.\n",
    "- Realiza cálculos de manera estática creando una gráfica de operaciones fija (programación declarativa), lo que lo hace muy **eficiente**.\n",
    "- Recientemente se han implentado muchos cambios, que se consolidarán en la versión 2.0.\n",
    "\n",
    "\n",
    "**PyTorch**\n",
    "- Desarrollada por Facebook. Se utiliza en la mayoría de sus servicios.\n",
    "- Tiene extensiones que le permiten ejecutarse de manera distribuida en distintos equipos y en celulares (CAFFE2).\n",
    "- Realiza cálculos de manera dinámica, crea una gráfica de computo que puede modificarse durante la ejecución (programación imperativa), lo que lo hace muy **flexible**.\n",
    "- Tiene extensiones que le permiten conectarse a Tensorboard.\n",
    "\n",
    "**Keras**\n",
    "- Librería de alto nivel que puede utilizar otras de bajo nivel como base: Tensorflow, Theano, CNTK.\n",
    "- Es sencilla y fácil de aprender pero con menor capacidad de configuración.\n",
    "- Tensorflow 2.0 incorporará a Keras de forma nativa para utilizar sus funciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Towards Data Science: About Train, Validation and Test Sets in Machine Learning](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7)\n",
    "- [Towards Data Science: A Concise History of Neural Networs (upto the 90s)](https://medium.com/@Jaconda/a-concise-history-of-neural-networks-2070655d3fec)\n",
    "- [Towards Data Science: The Perceptron Algorithm](https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975)\n",
    "- [Machine Learning Mastery: How to Configure the Number of Layers and Nodes in a Neural Network](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)\n",
    "- [Mohammed Bennamoun: Multi-Layer Perceptron and Backpropagation](https://www.slideshare.net/MohammedBennamoun/neural-networks-multilayer-perceptron-backpropagation)\n",
    "- [Patrick Winston (MIT): Neural Networks](https://www.youtube.com/watch?v=uXt8qF2Zzfo&list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi&index=12)\n",
    "- [Michael Nielsen: How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)\n",
    "- [Sebastian Ruder: An Overview of Gradient Descent Algorithms](http://ruder.io/optimizing-gradient-descent/)\n",
    "- [Python Programming Language: Tensorflow Datatypes](https://pythonprogramminglanguage.com/tensorflow-datatypes/)\n",
    "- [Tensorflow Documentation: Introduction to Low-Level APIs](https://www.tensorflow.org/guide/low_level_intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
